# -*- coding: utf-8 -*-
"""rdd_wc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-4-UKKR1_tU2_jlbbKkIre2mBIcHH4us
"""

!pip install --quiet pyspark

from pyspark import SparkConf, SparkContext
sc = SparkContext.getOrCreate(SparkConf().setMaster("local[*]"))

# parallelize some rdd, here a list of words
words = ['cat', 'rat', 'bat', 'rat', 'rat']
words_rdd = sc.parallelize(words, 1)
words_rdd.take(5)

# map operation to make k-v pair
rdd_tup = words_rdd.map(lambda word: (word, 1))
rdd_tup.take(5)

# reducebykey to get get frequency of individual words 
result = rdd_tup.reduceByKey(lambda x, y: x+y)
result.take(5)

# Filter for counts having animal name starting with 'r'
rats_only_count = result.filter(lambda x: x[0].startswith('r'))
rats_only_count.take(1)

# save result as text_file
result.saveAsTextFile('/content/word_freq.csv')

! cat /content/word_freq.csv/part-00000